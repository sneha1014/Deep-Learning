{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\nDeep Learning workflows\n1. Data\n2. Create a model\n3. Optimize model parameter (finding the beast weights)\n4. Save the trained model\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T07:56:45.076705Z","iopub.execute_input":"2024-12-18T07:56:45.077349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#importing libraries\nimport torch  #pytorch library that helps in building the deep learning algorithms\nfrom torch import nn  #nn- neural networks\nfrom torch.utils.data import DataLoader #performs the process of batching by loading the data\nfrom torchvision import datasets #downloads data\nfrom torchvision.transforms import ToTensor #data should be transformed to tensor\n#In dataloader we pass dataset which is combination of (X,Y) datapoints ","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.084870Z","iopub.execute_input":"2024-12-18T07:56:45.085113Z","iopub.status.idle":"2024-12-18T07:56:45.092725Z","shell.execute_reply.started":"2024-12-18T07:56:45.085094Z","shell.execute_reply":"2024-12-18T07:56:45.091793Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#download data\n#Inbuild dataset that python library has - FashionMNIST dataset\ntraining_data=datasets.FashionMNIST(root='data',train=True,download=True,transform=ToTensor())\ntest_data=datasets.FashionMNIST(root='data',train=False,download=True,transform=ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.093832Z","iopub.execute_input":"2024-12-18T07:56:45.094059Z","iopub.status.idle":"2024-12-18T07:56:45.198441Z","shell.execute_reply.started":"2024-12-18T07:56:45.094042Z","shell.execute_reply":"2024-12-18T07:56:45.197683Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"training_data","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.199559Z","iopub.execute_input":"2024-12-18T07:56:45.199851Z","iopub.status.idle":"2024-12-18T07:56:45.205256Z","shell.execute_reply.started":"2024-12-18T07:56:45.199829Z","shell.execute_reply":"2024-12-18T07:56:45.204322Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset FashionMNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.207642Z","iopub.execute_input":"2024-12-18T07:56:45.207910Z","iopub.status.idle":"2024-12-18T07:56:45.216230Z","shell.execute_reply.started":"2024-12-18T07:56:45.207890Z","shell.execute_reply":"2024-12-18T07:56:45.215550Z"},"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Dataset FashionMNIST\n    Number of datapoints: 10000\n    Root location: data\n    Split: Test\n    StandardTransform\nTransform: ToTensor()"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"#batching of data\nbatch_size=64\ntrain_dataloader= DataLoader(training_data,batch_size=batch_size)\ntest_dataloader= DataLoader(test_data,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.217339Z","iopub.execute_input":"2024-12-18T07:56:45.217658Z","iopub.status.idle":"2024-12-18T07:56:45.224032Z","shell.execute_reply.started":"2024-12-18T07:56:45.217629Z","shell.execute_reply":"2024-12-18T07:56:45.223310Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"for x,y in test_dataloader:  #Image - Colour image shape(batch_size, number of channel, length, width)\n    print (x.shape)          #Image - Black and white image- number of channels is 1\n    print (y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.225105Z","iopub.execute_input":"2024-12-18T07:56:45.225343Z","iopub.status.idle":"2024-12-18T07:56:45.243854Z","shell.execute_reply.started":"2024-12-18T07:56:45.225325Z","shell.execute_reply":"2024-12-18T07:56:45.243138Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([64, 1, 28, 28])\ntorch.Size([64])\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#creating model\ndevice= 'cuda' if torch.cuda.is_available() else 'cpu'#torch.cuda.is_available() checks for your system has gpu or cpu\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.244693Z","iopub.execute_input":"2024-12-18T07:56:45.244938Z","iopub.status.idle":"2024-12-18T07:56:45.250119Z","shell.execute_reply.started":"2024-12-18T07:56:45.244919Z","shell.execute_reply":"2024-12-18T07:56:45.249354Z"},"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):  #child class and nn. module is a parent class --(defined in the pytorch library)\n    def __init__(self): #declare the architecture\n        super().__init__() #initializes all variables of parent class\n        self.flatten=nn.Flatten() #converts 28x28 image into 764x1 vector\n        self.linear1=nn.Linear(28*28,512) #input of size of 28*28 converted to 512 dimension\n        #hidden layer 1\n        self.linear2=nn.Linear(512,512)  #converts 512 to 512 \n        #hidden layer 2\n        self.linear3=nn.Linear(512,10)  #converts 512 to output size 10\n        self.relu=nn.ReLU()  #activation fn\n    \n    #forward method does forward propogation\n    def forward(self,x): #used to pass inputs to neural network\n        #self has arrchitecture and x has data\n        x=self.flatten(x)\n        #x which contains data will be passed to flatten \n        x=self.linear1(x)\n        x=self.relu(x)\n        x=self.linear2(x)\n        x=self.relu(x)\n        x=self.linear3(x)\n        #from flaatten it goes to linear1, then to relu then to linear2....\n        #In between hidden layers, we can do any type of activation fn but atlast we need to be careful while performing activatn fn\n        #here as this is a classification problem we need to softmax at last but we are not dng bcz this will be performed in CrossEntropyLoss()\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.251109Z","iopub.execute_input":"2024-12-18T07:56:45.251362Z","iopub.status.idle":"2024-12-18T07:56:45.258886Z","shell.execute_reply.started":"2024-12-18T07:56:45.251340Z","shell.execute_reply":"2024-12-18T07:56:45.258124Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"model=NeuralNetwork()\nmodel=model.to(device) #copies your entire architecture to gpu","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.259897Z","iopub.execute_input":"2024-12-18T07:56:45.260205Z","iopub.status.idle":"2024-12-18T07:56:45.274295Z","shell.execute_reply.started":"2024-12-18T07:56:45.260184Z","shell.execute_reply":"2024-12-18T07:56:45.273472Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"#optimization-- gradient descent+backpropogation\nloss_fn=nn.CrossEntropyLoss()  # cross entropy loss fn has the capability to do softmax activation fn and loss fn that is the reason y we haven't done activation fn previously\noptimizer=torch.optim.SGD(model.parameters(),lr=1e-3)  #stochastic gradient desent","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:56:45.275242Z","iopub.execute_input":"2024-12-18T07:56:45.275476Z","iopub.status.idle":"2024-12-18T07:56:45.280082Z","shell.execute_reply.started":"2024-12-18T07:56:45.275453Z","shell.execute_reply":"2024-12-18T07:56:45.279215Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"'''\nSteps in gradient decent:\n1. Batch of input\n2. Pass it to model\n3. Compute loss fn\n4. Update weights\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T07:56:45.280953Z","iopub.execute_input":"2024-12-18T07:56:45.281214Z","iopub.status.idle":"2024-12-18T07:56:45.291126Z","shell.execute_reply.started":"2024-12-18T07:56:45.281187Z","shell.execute_reply":"2024-12-18T07:56:45.290529Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'\\nSteps in gradient decent:\\n1. Batch of input\\n2. Pass it to model\\n3. Compute loss fn\\n4. Update weights\\n'"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"#training\ndef train(dataloader,model,loss_fn,optimizer):\n    model.train() #putting model in training mode\n    for batch, (x,y) in enumerate(dataloader): #loads the data where (x,y) have batches of data\n        #sending data (x,y) to gpu\n        x=x.to(device)\n        y=y.to(device)\n        #input x will be passed to model and the forward method in architecture runs and gives some predictions\n        #compute predictions\n        pred=model(x)\n        #By predicted values compute loss\n        loss=loss_fn(pred,y)\n        \n        #after that do back propogation\n        loss.backward() #calculate gradients of the loss with respect to the model's parameters i.e dl/dw\n        optimizer.step() #updates the model parameters based on those gradients. ie Wnew=Wold-lr*dl/dw\n        optimizer.zero_grad() #clears the gradients for nxt time ie the new gradients are added to the existing gradients\n        \n        if batch %100==0:\n            print(f'Loss of model {loss.item()}')\n        \n        #loss.backward() is the powerful step bcz it will remember the track of forward pass and automatically comes back in same path ","metadata":{"execution":{"iopub.status.busy":"2024-12-18T07:59:21.412148Z","iopub.execute_input":"2024-12-18T07:59:21.412497Z","iopub.status.idle":"2024-12-18T07:59:21.418520Z","shell.execute_reply.started":"2024-12-18T07:59:21.412471Z","shell.execute_reply":"2024-12-18T07:59:21.417655Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def test(dataloader,model,loss_fn):\n  model.eval() #it is in test mode\n  test_loss, correct = 0,0\n  size = len(dataloader.dataset)\n  with torch.no_grad(): #What ever is inside this steps no gradient should be applied\n    for batch,(X,y) in enumerate(dataloader):\n      X,y = X.to(device), y.to(device)\n      pred = model(X) #10x1 vector\n      # print (pred.shape)\n      # print (pred.argmax(1))\n      # print (y)\n      # print ((pred.argmax(1) == y).type(torch.float).sum().item())\n      # break\n      test_loss += loss_fn(pred,y).item()\n      '''\n      pred.argmax(1) -- position of the maximum probability\n      torch.float\n      torch.int\n      torch.float32\n      '''\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n  print (f'Total correct {correct} out of {size}')\n  Accuracy = correct/size\n  print (f'Accuracy : {Accuracy*100}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T07:59:22.839856Z","iopub.execute_input":"2024-12-18T07:59:22.840172Z","iopub.status.idle":"2024-12-18T07:59:22.846397Z","shell.execute_reply.started":"2024-12-18T07:59:22.840146Z","shell.execute_reply":"2024-12-18T07:59:22.845584Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"epochs = 3\n\nfor t in range(epochs):\n  print ('Epoch---------------------------')\n  train(train_dataloader,model,loss_fn,optimizer)\n  test(test_dataloader, model, loss_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T07:59:23.660549Z","iopub.execute_input":"2024-12-18T07:59:23.661331Z","iopub.status.idle":"2024-12-18T07:59:47.519503Z","shell.execute_reply.started":"2024-12-18T07:59:23.661302Z","shell.execute_reply":"2024-12-18T07:59:47.518572Z"}},"outputs":[{"name":"stdout","text":"Epoch---------------------------\nLoss of model 2.3020730018615723\nLoss of model 2.2868471145629883\nLoss of model 2.272218942642212\nLoss of model 2.2659924030303955\nLoss of model 2.245800495147705\nLoss of model 2.2092368602752686\nLoss of model 2.2268576622009277\nLoss of model 2.1817915439605713\nLoss of model 2.17868971824646\nLoss of model 2.158397674560547\nTotal correct 4208.0 out of 10000\nAccuracy : 42.08\nEpoch---------------------------\nLoss of model 2.149186849594116\nLoss of model 2.1359856128692627\nLoss of model 2.0842831134796143\nLoss of model 2.10636568069458\nLoss of model 2.0498125553131104\nLoss of model 1.9909969568252563\nLoss of model 2.0289971828460693\nLoss of model 1.9410905838012695\nLoss of model 1.946912407875061\nLoss of model 1.8925796747207642\nTotal correct 5788.0 out of 10000\nAccuracy : 57.879999999999995\nEpoch---------------------------\nLoss of model 1.9046450853347778\nLoss of model 1.869931697845459\nLoss of model 1.7598949670791626\nLoss of model 1.8076472282409668\nLoss of model 1.6949586868286133\nLoss of model 1.6557968854904175\nLoss of model 1.6836410760879517\nLoss of model 1.5780811309814453\nLoss of model 1.6050634384155273\nLoss of model 1.5170997381210327\nTotal correct 6196.0 out of 10000\nAccuracy : 61.96\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"#Predictions\nclasses = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\n\nmodel.eval()\nX,y = test_data[0][0], test_data[0][1]\n\nwith torch.no_grad():\n  X = X.to(device)\n  pred = model(X)\n  predicted,actual = classes[pred[0].argmax(0)],classes[y]\n  print(f'Predicted {predicted}')\n  print(f'Actual {actual}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:01:49.670665Z","iopub.execute_input":"2024-12-18T08:01:49.671370Z","iopub.status.idle":"2024-12-18T08:01:49.702373Z","shell.execute_reply.started":"2024-12-18T08:01:49.671342Z","shell.execute_reply":"2024-12-18T08:01:49.701251Z"}},"outputs":[{"name":"stdout","text":"Predicted Ankle Boot\nActual Ankle Boot\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}